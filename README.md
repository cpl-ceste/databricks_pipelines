# Optimización de pipelines de datos en Databricks y Spark


## Sesión 1:  Fundamentos y diagnóstico de rendimiento 

• Cómo ejecuta Spark los pipelines (DAG, stages, tasks) 

•	Identificación de cuellos de botella: shuffles, skew, particiones 

•	Uso de herramientas como Spark UI, DAG Viewer y explain() 

## Sesión 2:  Técnicas de optimización 

• Buenas prácticas con código Spark (cache, filtros, joins, columnas) 

•	Optimización de particionado y tamaño de archivos 

•	Uso de Delta Lake, Z-Ordering y comandos OPTIMIZE 

•	Auto-optimizaciones de Databricks: AQE, Photon, autoscaling 

## Sesión 3:  Diseño de pipelines escalables y sostenibles

•	Modularización, parámetros y manejo de errores 

•	Orquestación con Databricks Workflows 

•	Control de costes y clusters eficientes 

•	Casos reales de optimización de pipelines 
